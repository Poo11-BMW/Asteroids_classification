# -*- coding: utf-8 -*-
"""Asteroid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19HlIx389V3No7Suxx0kViEm02l_D7FAW
"""

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('dark_background')
import seaborn as sns

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/nasa.csv')
df.head()

df.shape

df.info()

df = df.drop(['Neo Reference ID', 'Name', 'Orbit ID', 'Close Approach Date',
                        'Epoch Date Close Approach', 'Orbit Determination Date'] , axis = 1)
df.head()

hazardous_labels = pd.get_dummies(df['Hazardous'])
hazardous_labels

df = pd.concat([df, hazardous_labels], axis = 1)
df.head()

df = df.drop(['Hazardous'], axis = 1)
df.head()

df.info()

df['Orbiting Body'].value_counts()

df['Equinox'].value_counts()

df = df.drop(['Orbiting Body', 'Equinox'], axis = 1)

plt.figure(figsize = (20,20))
sns.heatmap(df.corr(),annot = True)

df = df.drop(['Est Dia in KM(max)', 'Est Dia in M(min)', 'Est Dia in M(max)', 'Est Dia in Miles(min)'
             ,'Est Dia in Miles(max)', 'Est Dia in Feet(min)', 'Est Dia in Feet(max)', 
             'Relative Velocity km per hr', 'Miles per hour', 'Miss Dist.(lunar)', 
             'Miss Dist.(kilometers)', 'Miss Dist.(miles)'], axis = 1)
df.head()

plt.figure(figsize = (20,20))
sns.heatmap(df.corr(),annot = True)

df.drop([False], axis = 1, inplace = True)

df.head()

df.describe()

""" **MODEL BUILDING**

"""

x = df.drop([True], axis = 1)
y = df[True].astype(int)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 0 , test_size = 0.2)

"""**RANDOM FOREST**"""

# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier

# creating a RF classifier
clf = RandomForestClassifier(n_estimators = 100)  
  
# Training the model on the training dataset
# fit function is used to train the model using the training sets as parameters
clf.fit(x_train, y_train)
  
# performing predictions on the test dataset
y_pred = clf.predict(x_test)
  
# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report , confusion_matrix  
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE Random forest MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))

importances_df = pd.DataFrame({"feature_names" : clf.feature_names_in_, 
                               "importances" : clf.feature_importances_})

g = sns.barplot(data=importances_df, 
                x="importances", 
                y="feature_names")
g.set_title("Feature importances", fontsize=14)
for value in g.containers:
    g.bar_label(value)

"""**NAIVE** **BAYES**"""

from sklearn.naive_bayes import GaussianNB
# instantiate the model
gnb = GaussianNB()
# fit the model
gnb.fit(x_train, y_train)

y_pred = gnb.predict(x_test)
# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report , confusion_matrix  
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE Naive Bayes MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))

from sklearn.inspection import permutation_importance
from sklearn.naive_bayes import GaussianNB

imps = permutation_importance(gnb, x_test, y_test)
print(imps.importances_mean)

g = sns.barplot(data=importances_df, 
                x="importances", 
                y="feature_names")
g.set_title("Feature importances", fontsize=14)
for value in g.containers:
    g.bar_label(value)

"""**SUPPORT VECTOR ALGORITHM**"""

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(x_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(x_test)

# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report 
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE Support Vector Algorithm MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))

"""**LOGISTIC REGRESSION**"""

from sklearn.linear_model import LogisticRegression
  
classifier = LogisticRegression(random_state = 0)
classifier.fit(x_train, y_train)
y_pred = classifier.predict(x_test)

# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report 
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE Logistic Regression MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))

"""**K- NEAREST NEIGHBOUR**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=7)  
knn.fit(x_train, y_train) 
# Predict on dataset which model has not seen before
y_pred=knn.predict(x_test)

# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report 
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE K-Nearest Neighbors MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))

"""**XGBOOST**"""

from xgboost import XGBClassifier
xbg_model = XGBClassifier()
xbg_model.fit(x_train, y_train)
y_pred=xbg_model.predict(x_test)

# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report 
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE XGBoost MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))

"""**ADABOOST**"""

from sklearn.ensemble import AdaBoostClassifier
# Create adaboost classifer object
abc = AdaBoostClassifier(n_estimators=50,
                         learning_rate=1)
# Train Adaboost Classifer
model = abc.fit(x_train, y_train)

#Predict the response for test dataset
y_pred = model.predict(x_test)

# metrics are used to find accuracy or error
from sklearn.metrics import accuracy_score, classification_report 
  
# using metrics module for accuracy calculation
acc = accuracy_score(y_test, y_pred)
print("ACCURACY OF THE ADABoost MODEL: ",str(np.round(acc*100, 2))+'%' )
print(classification_report(y_test,y_pred))